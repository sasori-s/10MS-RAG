# üáßüá© Bangla-English RAG System from Text Book for 10MS- README

A Retrieval-Augmented Generation (RAG) system for Bangla and English documents which is on Bangla text book using OCR, chunking, semantic embeddings, and Gemini 2.0 Flash for answer generation.

---

## üì¶ Tools, Libraries, and Packages

| Tool/Library           | Purpose                                         |
| ---------------------- | ----------------------------------------------- |
| `pdf2image`            | Convert PDF pages to images                     |
| `pytesseract`          | OCR for extracting Bangla/English text          |
| `LangChain`            | Pipeline for RAG, memory, chunking              |
| `ChromaDB`             | Vector database for storing document embeddings |
| `Google embedding-001` | Embedding generation                            |
| `Gemini 2.0 Flash`     | LLM for final answer generation                 |
| `RunnablePassthrough`  | For short-term memory in LangChain              |

---

## ‚öôÔ∏è Setup Guide

### 1. Text Extraction

- Used `pdf2image` to convert PDF pages to image.
- Used `pytesseract` (Google Tesseract OCR) to extract text.
- This approach is more accurate for Bangla PDFs than PyPDF2, pdfminer, or pdfplumber due to formatting issues.

### 2. Chunking

- Library: LangChain's `RecursiveCharacterTextSplitter`
- Config:
  - `chunk_size=1000`
  - `chunk_overlap=200`
- Benefits:
  - Keeps semantic boundaries intact.
  - Avoids context fragmentation during retrieval.

### 3. Embedding + Storage

- Initially used `gpt4all` embeddings ‚Üí poor quality.
- Switched to `Google's embedding-001` ‚Üí better multilingual support.
- Stored using `ChromaDB`.

### 4. Short-Term Memory

- Used `RunnablePassthrough` for passing chat history manually.
- Helps maintain conversational flow.

---

## üîç Sample Queries & Outputs

### üîπ Bangla

**Q:** "‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶§‡ßá ‡¶ï‡¶≤‡ßç‡¶≤‡¶æ‡¶®‡ßÄ‡¶∞ ‡¶Æ‡¶§‡¶æ‡¶Æ‡¶§ ‡¶ï‡¶ø ‡¶õ‡¶ø‡¶≤‡ßã?‚Äù\
**A:** ‚Äú‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá‡¶®, ‡¶è‡¶á ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡ßç‡¶§ ‡¶§‡¶•‡ßç‡¶Ø ‡¶®‡ßá‡¶á‡•§ ‡¶¨‡¶ø‡ßü‡ßá‡¶§‡ßá ‡¶ï‡¶≤‡ßç‡¶≤‡¶æ‡¶®‡ßÄ‡¶∞ ‡¶Æ‡¶§‡¶æ‡¶Æ‡¶§‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∑‡ßü‡ßá ‡¶ï‡ßã‡¶®‡ßã ‡¶§‡¶•‡ßç‡¶Ø ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶¶‡ßá‡¶ì‡ßü‡¶æ ‡¶®‡ßá‡¶á, ‡¶§‡¶¨‡ßá ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡¶ø‡ßü‡ßá ‡¶≠‡ßá‡¶ô‡ßá ‡¶Ø‡¶æ‡¶ì‡ßü‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï ‡¶¶‡¶ø‡ßü‡ßá ‡¶¨‡¶ø‡ßü‡ßá ‡¶®‡¶æ ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶§‡ßç‡¶Æ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶∞‡¶∂‡ßÄ‡¶≤ ‡¶π‡¶ì‡ßü‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶∑‡ßü‡ßá ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶§‡¶•‡ßç‡¶Ø ‡¶Ü‡¶õ‡ßá‡•§‚Äù

**Q:** "‡¶ó‡¶π‡¶®‡¶æ ‡¶ó‡ßÅ‡¶≤‡¶æ ‡¶ï‡¶ø ‡¶≠‡¶æ‡¶∞‡ßÄ ‡¶õ‡¶ø‡¶≤‡ßã?‚Äù\
**A:** ‚Äú‡¶π‡ßç‡¶Ø‡¶æ‡¶Å, ‡¶ó‡¶π‡¶®‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≠‡¶æ‡¶∞‡ßÄ ‡¶õ‡¶ø‡¶≤‡•§ ‡¶ó‡¶π‡¶®‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶™‡¶ø‡¶§‡¶æ‡¶Æ‡¶π‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶Ü‡¶Æ‡¶≤‡ßá‡¶∞ ‡¶õ‡¶ø‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶Ø‡ßá‡¶Æ‡¶® ‡¶Æ‡ßã‡¶ü‡¶æ ‡¶§‡ßá‡¶Æ‡¶®‡¶ø ‡¶≠‡¶æ‡¶∞‡ßÄ ‡¶õ‡¶ø‡¶≤‡•§‚Äù

### üîπ English

**Q:** "What was Kallani's opinion about the marriage?"  
**A:** "Please note that there isn't enough information provided to answer this question. There's no mention of Kallani's opinion about the marriage here. However, there is some information about a marriage being broken off due to dowry demands, and about choosing self-reliance over giving dowry."

**Q:** "Were the ornaments heavy?"  
**A:** "Yes, the ornaments were heavy. They were from the grandmother's time and were not only thick but also heavy."

---

<!-- ## üìò API Documentation (Sample)

### `POST /query`

**Description:** Accepts a query and returns generated answer.

**Request:**

```json
{
  "question": "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶∏‡¶æ‡¶π‡¶ø‡¶§‡ßç‡¶Ø‡ßá‡¶∞ ‡¶á‡¶§‡¶ø‡¶π‡¶æ‡¶∏ ‡¶ï‡¶ø?",
  "lang": "bn"
}
```

**Response:**

```json
{
  "answer": "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶∏‡¶æ‡¶π‡¶ø‡¶§‡ßç‡¶Ø‡ßá‡¶∞ ‡¶á‡¶§‡¶ø‡¶π‡¶æ‡¶∏ ‡¶™‡ßç‡¶∞‡¶æ‡¶ö‡ßÄ‡¶® ‡¶Ø‡ßÅ‡¶ó ‡¶•‡ßá‡¶ï‡ßá ‡¶Ü‡¶ß‡ßÅ‡¶®‡¶ø‡¶ï ‡¶Ø‡ßÅ‡¶ó ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶™‡¶ø ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶Ø‡ßÅ‡¶ó ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶Ø‡ßÅ‡¶ó ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶Ø‡ßÅ‡¶ó ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶Ø‡ßÅ‡¶ó..."
}
``` -->

---

## üìä Evaluation Matrix

| Metric            | Description                                | Result/Status                        |
| ----------------- | ------------------------------------------ | ------------------------------------ |
| Groundedness      | Answer reflects retrieved chunk            | ‚úÖ Mostly grounded (manual check)     |
| Relevance         | Retrieved chunk is aligned with user query | ‚úÖ High with `embedding-001`          |
| Cosine Similarity | Between chunk & answer embeddings          | ‚úÖ Avg. > 0.85                        |
| Human QA Score    | Manual QA on 20 queries                    | Avg. 4.3/5 (Bangla), 4.5/5 (English) |

---

## ‚ùì Common Questions Answered

### 1. What method or library did you use to extract text, and why?

- Used `pdf2image` + `pytesseract` for OCR.
- Other libraries failed to retain formatting and text order for Bangla content.

### 2. What chunking strategy did you use?

- RecursiveCharacterTextSplitter
- `chunk_size=1000`, `overlap=200`
- Prevents semantic breaks and ensures full context in each chunk.

### 3. What embedding model did you use and why?

- `Google embedding-001`
- Handles multilingual content, returns contextually rich vector representations.

### 4. How are you comparing queries with stored chunks?

- Cosine similarity between embedding vectors in `ChromaDB`.

### 5. How do you ensure meaningful comparisons?

- High-quality embeddings
- Overlapping semantic chunks
- Short-term memory (RunnablePassthrough)
- Fallback to generic answers or clarification if query is vague

### 6. Are results relevant?

- ‚úÖ Yes, especially after switching to Google embeddings
- Could be improved further with better chunking, query rewriting, and larger corpora.

---

## ‚úÖ Future Improvements

- Add sentence-level chunking with semantic labeling
- Integrate query rewriting / clarification
- Fine-tune multilingual embeddings for Bangla domain

